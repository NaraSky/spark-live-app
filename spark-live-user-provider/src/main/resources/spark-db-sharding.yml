dataSources:
  user: ## 物理数据源 “user”，用于实际的 JDBC 连接
    dataSourceClassName: com.zaxxer.hikari.HikariDataSource  # 使用 HikariCP 连接池
    driver-class-name: com.mysql.cj.jdbc.Driver             # MySQL 驱动
    # JDBC URL 包含字符集设置，指向 spark_live_user 数据库
    jdbcUrl: jdbc:mysql://117.72.33.162:3306/spark_live_user?useUnicode=true&characterEncoding=utf8
    username: root          # 数据库用户名
    password: mysql_1120    # 数据库密码

    # HikariCP 池配置
    idle-timeout: 5         # 最大空闲时间，单位：分钟，超过则回收连接
    minimum-idle: 100       # 最小空闲连接数，保证在低负载时仍保留一定数量的连接
    pool-name: spark-db-user# 池名称，便于监控区分
    maximum-pool-size: 1000 # 最大连接数上限
    connection-timeout: 30000   # 获取连接的超时时间，单位：毫秒
    connection-init-sql: SELECT 1   # 连接初始化执行的 SQL，用于检查连通性
    connection-test-query: SELECT 1 # 测试连接可用性的 SQL

rules:
  - !SINGLE
    defaultDataSource: user        # 非分库分表场景下，使用的默认数据源

  - !SHARDING
    tables:
      t_user:
        # 实际物理节点，0～99 共 100 张分表，命名为 t_user_00 ... t_user_99
        actualDataNodes: user.t_user_${(0..99).collect(){ it.toString().padLeft(2,'0') }}
        tableStrategy:
          standard:
            shardingColumn: user_id      # 分片键，按 user_id 取模
            shardingAlgorithmName: t_user-inline

    shardingAlgorithms:
      t_user-inline:
        type: INLINE                   # 内联算法
        props:
          # 算法表达式：user_id % 100，然后左侧补齐两位数字
          algorithm-expression: t_user_${(user_id % 100).toString().padLeft(2,'0')}

props:
  sql-show: true  # 打印执行的 SQL 到控制台，便于排查分片后的实际 SQL
